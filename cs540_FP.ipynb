{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import io\n",
    "import speech_recognition as sr\n",
    "\n",
    "# you'll need to run nltk.download() and download all packages\n",
    "#nltk.download_shell()\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "nltk.data.path.append('D:\\\\JacobSchool\\\\CS540\\\\nltk_data')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import ConditionalFreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets from http://www.iaees.org/publications/journals/selforganizology/articles/2016-3(3)/algorithm-to-transform-natural-language-into-SQL-queries.pdf\n",
    "Escape Word Set<br/>\n",
    "Expression Mapping Set<br/>\n",
    "Noun Set<br/>\n",
    "Verb Set<br/>\n",
    "Semantic Set<br/>\n",
    "Variable Set<br/>\n",
    "Relation Set<br/>\n",
    "Attribute Set<br/>\n",
    "Conjunction Set<br/>\n",
    "This is all the sets for words and rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "escape_words = set(stopwords.words('english'))#[\"a\", \"an\", \"the\", \"which\", \"is\", \"of\", \"with\", \"to\", \"for\", \"are\", \"and\", \"should\", \"be\"]\n",
    "\n",
    "rules_on_top_of = []\n",
    "\n",
    "rules_side_by_side = []\n",
    "\n",
    "nouns = [\"block\", \"wildcard\", \"block0\", \"block1\", \"block2\", \"block3\", \"block4\", \"block5\", \"block6\", \"block7\", \"block8\", \"block9\" \\\n",
    "         \"block10\", \"block11\", \"block12\", \"block13\", \"block14\", \"block15\", \"block16\", \"block17\", \"block18\", \"block19\" \\\n",
    "         \"block20\", \"block21\", \"block22\", \"block23\", \"block24\", \"block25\", \"block26\", \"block27\", \"block28\", \"block29\" \\\n",
    "         \"block30\", \"block31\", \"block32\", \"block33\", \"block34\", \"block35\", \"block36\", \"block37\", \"block38\", \"block39\" \\\n",
    "         \"block40\", \"block41\", \"block42\", \"block43\", \"block44\", \"block45\", \"block46\", \"block47\", \"block48\", \"block49\" \\\n",
    "         \"block50\", \"block51\", \"block52\", \"block53\", \"block54\", \"block55\", \"block56\", \"block57\", \"block58\", \"block59\" \\\n",
    "         \"block60\", \"block61\", \"block62\", \"block63\", \"block64\", \"block65\", \"block66\", \"block67\", \"block68\", \"block69\" \\\n",
    "         \"block70\", \"block71\", \"block72\", \"block73\", \"block74\", \"block75\", \"block76\", \"block77\", \"block78\", \"block79\" \\\n",
    "         \"block80\", \"block81\", \"block82\", \"block83\", \"block84\", \"block85\", \"block86\", \"block87\", \"block88\", \"block89\" \\\n",
    "         \"block90\", \"block91\", \"block92\", \"block93\", \"block94\", \"block95\", \"block96\", \"block97\", \"block98\", \"block99\" \\\n",
    "         \"wildcard0\", \"wildcard1\", \"wildcard2\", \"wildcard3\", \"wildcard4\", \"wildcard5\", \"wildcard6\", \"wildcard7\", \"wildcard8\", \"wildcard9\" \\\n",
    "         \"wildcard10\", \"wildcard11\", \"wildcard12\", \"wildcard13\", \"wildcard14\", \"wildcard15\", \"wildcard16\", \"wildcard17\", \"wildcard18\", \"wildcard19\" \\\n",
    "         \"wildcard20\", \"wildcard21\", \"wildcard22\", \"wildcard23\", \"wildcard24\", \"wildcard25\", \"wildcard26\", \"wildcard27\", \"wildcard28\", \"wildcard29\" \\\n",
    "         \"wildcard30\", \"wildcard31\", \"wildcard32\", \"wildcard33\", \"wildcard34\", \"wildcard35\", \"wildcard36\", \"wildcard37\", \"wildcard38\", \"wildcard39\" \\\n",
    "         \"wildcard40\", \"wildcard41\", \"wildcard42\", \"wildcard43\", \"wildcard44\", \"wildcard45\", \"wildcard46\", \"wildcard47\", \"wildcard48\", \"wildcard49\" \\\n",
    "         \"wildcard50\", \"wildcard51\", \"wildcard52\", \"wildcard53\", \"wildcard54\", \"wildcard55\", \"wildcard56\", \"wildcard57\", \"wildcard58\", \"wildcard59\" \\\n",
    "         \"wildcard60\", \"wildcard61\", \"wildcard62\", \"wildcard63\", \"wildcard64\", \"wildcard65\", \"wildcard66\", \"wildcard67\", \"wildcard68\", \"wildcard69\" \\\n",
    "         \"wildcard70\", \"wildcard71\", \"wildcard72\", \"wildcard73\", \"wildcard74\", \"wildcard75\", \"wildcard76\", \"wildcard77\", \"wildcard78\", \"wildcard79\" \\\n",
    "         \"wildcard80\", \"wildcard81\", \"wildcard82\", \"wildcard83\", \"wildcard84\", \"wildcard85\", \"wildcard86\", \"wildcard87\", \"wildcard88\", \"wildcard89\" \\\n",
    "         \"wildcard90\", \"wildcard91\", \"wildcard92\", \"wildcard93\", \"wildcard94\", \"wildcard95\", \"wildcard96\", \"wildcard97\", \"wildcard98\", \"wildcard99\" ]\n",
    "\n",
    "verbs_top = [\"top\", \"above\", \"over\", \"on\"]\n",
    "verbs_below = [\"below\", \"underneath\",  \"under\"]\n",
    "verbs_side = [\"side\", \"neighboring\", \"beside\", \"next\"]\n",
    "\n",
    "variables_colors = [\"amber\", \"amethyst\", \"apricot\", \"aquamarine\", \"azure\", \"beige\", \"black\", \"blue\", \"blush\", \"bronze\", \"brown\", \"burgundy\", \"byzantium\", \"carmine\", \"cerise\", \"cerulean\", \"champagne\", \"chocolate\", \"coffee\", \"copper\", \"coral\", \"crimson\", \"cyan\", \"emerald\", \"erin\", \"gold\", \"gray\", \"green\", \"harlequin\", \"indigo\", \"ivory\", \"jade\", \"lavender\", \"lemon\", \"lilac\", \"lime\", \"magenta\", \"maroon\", \"mauve\", \"navy\", \"ochre\", \"olive\", \"orange\", \"orchid\", \"peach\", \"pearl\", \"periwinkle\", \"pink\", \"plum\", \"puce\", \"purple\", \"raspberry\", \"red\", \"rose\", \"ruby\", \"salmon\", \"sangria\", \"sapphire\", \"scarlet\", \"silver\", \"tan\", \"taupe\", \"teal\", \"turquoise\", \"ultramarine\", \"violet\", \"viridian\", \"white\", \"yellow\"]\n",
    "variables_location = [\"0\",\"zero\",\"1\", \"one\", \"2\", \"two\", \"3\", \"three\", \"4\", \"four\", \"5\", \"five\", \"6\", \"six\", \"7\", \"seven\", \"8\", \"eight\", \"9\", \"nine\"]\n",
    "loc_options = [\"move\", \"location\", \"spot\", \"position\", \"address\", \"place\", \"locality\", \"point\", \"placement\", \"locale\", \"setting\", \"bearings\", \"bearing\", \"venue\", \"is\", \"at\"]\n",
    "\n",
    "#position, place, situation, site, locality, locale, spot, whereabouts, point, placement; scene, setting, area, environment; bearings, orientation; venue, address;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Tags:<br/>\n",
    "NN &rightarrow; Noun<br/>\n",
    "VT &rightarrow; Verb Top<br/>\n",
    "VB &rightarrow; Verb Below<br/>\n",
    "VS &rightarrow; Verb Side<br/>\n",
    "VarC &rightarrow; Variable Color<br/>\n",
    "VarL &rightarrow; Variable Location<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBlockWorld(tagged_sentence, outputfile):\n",
    "    block1=\"\"\n",
    "    block2=\"\"\n",
    "    relation=\"\"\n",
    "    command=\"\"\n",
    "    location=\"\"\n",
    "    color=\"\"\n",
    "    swap_on_top_of = False\n",
    "    print('tagged sentence')\n",
    "    print(tagged_sentence)\n",
    "    #Find the first block, should be the block\n",
    "    for ts in tagged_sentence:\n",
    "        if (ts[1] == \"VT\"):\n",
    "            relation = \"on-top-of\"\n",
    "        \n",
    "        if (ts[1] == \"VS\"):\n",
    "            relation = \"side-by-side\"\n",
    "        \n",
    "        if (ts[1] == \"VB\"):\n",
    "            swap_on_top_of = True\n",
    "            relation = \"on-top-of\"\n",
    "            \n",
    "        if (ts[1] == \"VarL\"):\n",
    "            if(location==\"\"): \n",
    "                location+=ts[0]\n",
    "            else:\n",
    "                location+=(\" \"+ts[0])\n",
    "            \n",
    "        \n",
    "        if ((\"block\" in ts[0]) or (\"wildcard\" in ts[0])) and block1 == \"\":\n",
    "            block1=ts[0]\n",
    "        \n",
    "        if (ts[0] != block1) and ((\"block\" in ts[0]) or (\"wildcard\" in ts[0])):\n",
    "                block2=ts[0]\n",
    "        if (ts[1] == \"VarC\"):\n",
    "            color = ts[0]\n",
    "            \n",
    "\n",
    "    thecommand = \"\"\n",
    "    #Create the command for an is relation\n",
    "    if block1 and block2 and relation:\n",
    "        if swap_on_top_of:\n",
    "            thecommand = \"(is %s %s %s)\" %(block2, block1, relation)\n",
    "        else:\n",
    "            thecommand = \"(is %s %s %s)\" %(block1, block2, relation)\n",
    "    \n",
    "    if block1 and color:\n",
    "        thecommand = \"(has %s color %s)\" % (block1,color)\n",
    "\n",
    "    if block1 and location and (len(location)==5):\n",
    "            thecommand = \"(has %s location %s)\" % (block1,location)\n",
    "\n",
    "        \n",
    "    if thecommand != \"\":\n",
    "        print(thecommand)\n",
    "        with open(outputfile, \"a\") as myfile:\n",
    "            myfile.write(thecommand+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_command(outputfile, block1, block2, relation, color, location, swap_on_top_of):\n",
    "    print(\"format_command\")\n",
    "    print(block1 + \" \" + block2 + relation)\n",
    "    try:\n",
    "        thecommand = \"\"\n",
    "\n",
    "        #Create the command for an is relation\n",
    "        if block1 and block2 and relation:\n",
    "            if swap_on_top_of:\n",
    "                thecommand = \"(is %s %s %s)\" %(block2, block1, relation)\n",
    "            else:\n",
    "                thecommand = \"(is %s %s %s)\" %(block1, block2, relation)\n",
    "\n",
    "        if block1 and color:\n",
    "            thecommand = \"(has %s color %s)\" % (block1,color)\n",
    "\n",
    "        if block1 and location and (len(location)==3):\n",
    "                thecommand = \"(has %s location %s %s %s)\" % (block1,location[0],location[1],location[2])\n",
    "\n",
    "\n",
    "        if thecommand != \"\":\n",
    "            print(thecommand)\n",
    "            with open(outputfile, \"a\") as myfile:\n",
    "                myfile.write(thecommand+\"\\n\")\n",
    "            return \"SUCCESS\"\n",
    "    except:\n",
    "        return \"FAILURE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processLocation(tagged_sentence):\n",
    "        m_grammar = \"\"\"LOCATION:  {<CD><CD><CD>}\"\"\"\n",
    "        chunkParser = nltk.RegexpParser(m_grammar)\n",
    "        tree = chunkParser.parse(tagged_sentence)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == \"LOCATION\":\n",
    "                subtree.leaves()[0][0]\n",
    "                y=subtree.leaves()[1][0]\n",
    "                z=subtree.leaves()[2][0]\n",
    "                #print(\"LOCATION: \"+str(subtree.leaves()[]))\n",
    "              \n",
    "        return str(str(x)+ \" \"+str(y)+\" \"+str(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkBlocks(words):\n",
    "        parts_of_speech = []\n",
    "        parts_speach = nltk.pos_tag(words)\n",
    "        parts_of_speech.append(parts_speach)\n",
    "        \n",
    "        p=enumerate_parts(parts_of_speech)\n",
    "        m_grammar = \"\"\"BLOCK:  {<BNN><CD>}\"\"\"\n",
    "        chunkParser = nltk.RegexpParser(m_grammar)\n",
    "        tree = chunkParser.parse(p)\n",
    "        blockChanged=False\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == \"BLOCK\":\n",
    "                indexToReplace=parts_speach.index(subtree.leaves()[0])\n",
    "                parts_speach.pop(indexToReplace+1)\n",
    "                block=str(subtree.leaves()[0][0]+subtree.leaves()[1][0])\n",
    "                parts_speach[indexToReplace]=(block,\"BNN\")\n",
    "                blockChanged=True\n",
    "                \n",
    "        if(blockChanged):\n",
    "            temp=[]\n",
    "            for i in parts_speach:\n",
    "                temp.append(i[0])\n",
    "            words=temp\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_parts(parts_of_speech):\n",
    "    \n",
    "    #for p in parts_of_speech:\n",
    "    for i,w in enumerate(parts_of_speech):\n",
    "        if(w[0] in nouns):\n",
    "            tw = list(w)\n",
    "            tw[1]='BNN'\n",
    "            w=tuple(tw)\n",
    "            parts_of_speech[i]=w\n",
    "        elif(w[0] in variables_colors):\n",
    "            tw = list(w)\n",
    "            tw[1]='VARC'\n",
    "            w=tuple(tw)\n",
    "            parts_of_speech[i]=w\n",
    "        elif(w[0] in verbs_top):\n",
    "            tw = list(w)\n",
    "            tw[1]='VT'\n",
    "            w=tuple(tw)\n",
    "            parts_of_speech[i]=w\n",
    "        elif(w[0] in verbs_below):\n",
    "            tw = list(w)\n",
    "            tw[1]='VB'\n",
    "            w=tuple(tw)\n",
    "            parts_of_speech[i]=w\n",
    "        elif(w[0] in verbs_side):\n",
    "            tw = list(w)\n",
    "            tw[1]='VS'\n",
    "            w=tuple(tw)\n",
    "            parts_of_speech[i]=w\n",
    "        elif(w[0] in loc_options):\n",
    "            tw = list(w)\n",
    "            tw[1]='VARL'\n",
    "            w=tuple(tw)\n",
    "            parts_of_speech[i]=w\n",
    "        #Not needed the CD tag represents a number\n",
    "        #elif(w[0] in variables_numbers):\n",
    "        #    tw = list(w)\n",
    "        #    tw[1]='INT'\n",
    "        #    w=tuple(tw)\n",
    "        #    p[i]=w\n",
    "    #return parts_of_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkParts(p):\n",
    "        m_grammar = \"\"\"ONTOP: {<VT>.*}\n",
    "                        BOTTOM: {<VB>.*}\n",
    "                        LOCATION: {<VARL>.*<.*>.*<CD>.*<CD>.*<CD>}\n",
    "                                {<CD>.*<CD>.*<CD>}\n",
    "                        SIDE: {<VS>.*}\n",
    "                        BLOCK:  {<BNN>.*<CD>}\n",
    "                                {<BNN>?}\n",
    "                        COLOR: {<VARC.*>}\"\"\"\n",
    "        \n",
    "        #[('block', 'BNN'), ('23', 'CD'), ('goes', 'VBZ'), ('next', 'VS'), ('to', 'TO'), ('block', 'BNN'), ('23', 'CD')]\n",
    "        \n",
    "        print(p)\n",
    "        #grammar = ('''Location: {<NN>*<CD>*<CD>*<CD>} # NP''')\n",
    "        chunkParser = nltk.RegexpParser(m_grammar)\n",
    "        return chunkParser.parse(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partsOfSpeechTag(words, outputfile):\n",
    "    print(\"The words are:\" + str(words))\n",
    "    \n",
    "    #Part of Speech tagging    \n",
    "    parts_speech = nltk.pos_tag(words)\n",
    "    print(parts_speech)\n",
    "    #parts_of_speech.append(parts_speach)\n",
    "        \n",
    "    print(\"\\nParts of Speech for each sentence\")\n",
    "    #for p in parts_speech:\n",
    "    print(\"The Parts of Speech:\")\n",
    "    print(parts_speech)\n",
    "    enumerate_parts(parts_speech)\n",
    "    tree = chunkParts(parts_speech)\n",
    "    \n",
    "    location = []\n",
    "    block_1 = \"\"\n",
    "    block_2 = \"\"\n",
    "    color = \"\"\n",
    "    relation = \"\"\n",
    "    \n",
    "    swap_on_top_of = False\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() == \"LOCATION\":\n",
    "            print(\"LOCATION: \"+str(subtree.leaves()))\n",
    "            loc_values = subtree.leaves()[-3:]\n",
    "            location.append(loc_values[0][0])\n",
    "            location.append(loc_values[1][0])\n",
    "            location.append(loc_values[2][0])\n",
    "            print(location)\n",
    "        if subtree.label() == \"BLOCK\":\n",
    "            print(\"BLOCK: \"+str(subtree.leaves()))\n",
    "            if(block_1==\"\"):\n",
    "                block_1 = subtree.leaves()[0][0]\n",
    "                if(len(subtree.leaves())>1):\n",
    "                    block_1 += subtree.leaves()[1][0]\n",
    "                print(\"Block_1: \" + block_1)\n",
    "            elif(block_2==\"\"):\n",
    "                block_2 = subtree.leaves()[0][0]\n",
    "                if(len(subtree.leaves())>1):\n",
    "                    block_2 += subtree.leaves()[1][0]\n",
    "                print(\"Block_2: \" + block_2)\n",
    "        if subtree.label() == \"COLOR\":\n",
    "            print(\"COLOR: \"+str(subtree.leaves()))\n",
    "            color = subtree.leaves()[0][0]\n",
    "            print(color)\n",
    "        if subtree.label() == \"ONTOP\" or subtree.label() == \"BOTTOM\":\n",
    "            if subtree.label() == \"BOTTOM\":\n",
    "                swap_on_top_of = True\n",
    "            relation = \"on-top-of\"\n",
    "            print(\"ONTOP: \"+str(subtree.leaves()))\n",
    "            t_grammar = \"\"\"BLOCK:  {<BNN>.*<CD>}\n",
    "                                {<BNN>?}\"\"\"\n",
    "            cparse = nltk.RegexpParser(t_grammar)\n",
    "            top_tree = cparse.parse(subtree.leaves())\n",
    "            print(top_tree)\n",
    "            if(block_2==\"\"):\n",
    "                for t_tree in top_tree.subtrees():\n",
    "                    if t_tree.label() == \"BLOCK\":\n",
    "                        print(\"TOP BLOCK: \"+str(t_tree.leaves()))\n",
    "                        block_2 = t_tree.leaves()[0][0]\n",
    "                        if(len(t_tree.leaves())>1):\n",
    "                            block_2 += t_tree.leaves()[1][0]\n",
    "                        print(\"Block_2: \" + block_2)\n",
    "        if subtree.label() == \"SIDE\":\n",
    "            relation = \"side-by-side\"\n",
    "            print(\"SIDE: \"+str(subtree.leaves()))\n",
    "                    \n",
    "    return format_command(outputfile, block_1, block_2, relation, color, location, swap_on_top_of)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readinfile(inputfile, outputfile):\n",
    "    #os.remove(inputfile) if os.path.exists(inputfile) else None\n",
    "    os.remove(outputfile) if os.path.exists(outputfile) else None\n",
    "\n",
    "    commandFile = open(inputfile) \n",
    "    data = commandFile.read()# Use this to read file content as a stream: \n",
    "    commandFile.close()\n",
    "    \n",
    "    cfdist = ConditionalFreqDist()\n",
    "    \n",
    "    sentences = sent_tokenize(data)\n",
    "    #print(sentences)\n",
    "    #parts_of_speech = []\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence)\n",
    "        temp = []\n",
    "        for w in words:\n",
    "            temp.append(w.lower())\n",
    "        words = temp[0:-1]\n",
    "        \n",
    "        #Parts of Speech tagging\n",
    "        if(partsOfSpeechTag(words, outputfile)==\"SUCCESS\"):\n",
    "        \n",
    "        #if(format_command(outputfile, block_1, block_2, relation, color, location, swap_on_top_of)==\"SUCCESS\"):\n",
    "             condition = len(words)\n",
    "             cfdist[condition][\"SUCCESS\"] += 1\n",
    "             #print(condition)\n",
    "        else:\n",
    "             condition = len(words)\n",
    "             cfdist[condition][\"Fail\"] += 1\n",
    "             #print(condition)\n",
    "        print()\n",
    "    \n",
    "    for f in cfdist:\n",
    "        for k in cfdist[f]:\n",
    "            print(str(f)+\": \" +str(k))\n",
    "            #print(\"Frequency of\", f, cfdist.freq(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Speech Reecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()\n",
    "recording = sr.AudioFile('Recording.wav')\n",
    "with recording as source:\n",
    "    audio = r.record(source)\n",
    "recording_str = r.recognize_google(audio)\n",
    "new_file=open(\"nlp_tests/Recording.txt\",mode=\"w\",encoding=\"utf-8\")\n",
    "new_file.write(recording_str)\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The words are:['block', '1', 'has', 'color', 'red']\n",
      "[('block', 'NN'), ('1', 'CD'), ('has', 'VBZ'), ('color', 'NN'), ('red', 'JJ')]\n",
      "\n",
      "Parts of Speech for each sentence\n",
      "The Parts of Speech:\n",
      "[('block', 'NN'), ('1', 'CD'), ('has', 'VBZ'), ('color', 'NN'), ('red', 'JJ')]\n",
      "[('block', 'BNN'), ('1', 'CD'), ('has', 'VBZ'), ('color', 'NN'), ('red', 'VARC')]\n",
      "BLOCK: [('block', 'BNN'), ('1', 'CD')]\n",
      "Block_1: block1\n",
      "COLOR: [('red', 'VARC')]\n",
      "red\n",
      "format_command\n",
      "block1 \n",
      "(has block1 color red)\n",
      "\n",
      "The words are:['block2', 'has', 'location', '8', '3', '1']\n",
      "[('block2', 'NN'), ('has', 'VBZ'), ('location', 'NN'), ('8', 'CD'), ('3', 'CD'), ('1', 'CD')]\n",
      "\n",
      "Parts of Speech for each sentence\n",
      "The Parts of Speech:\n",
      "[('block2', 'NN'), ('has', 'VBZ'), ('location', 'NN'), ('8', 'CD'), ('3', 'CD'), ('1', 'CD')]\n",
      "[('block2', 'BNN'), ('has', 'VBZ'), ('location', 'VARL'), ('8', 'CD'), ('3', 'CD'), ('1', 'CD')]\n",
      "BLOCK: [('block2', 'BNN')]\n",
      "Block_1: block2\n",
      "LOCATION: [('8', 'CD'), ('3', 'CD'), ('1', 'CD')]\n",
      "['8', '3', '1']\n",
      "format_command\n",
      "block2 \n",
      "(has block2 location 8 3 1)\n",
      "\n",
      "The words are:['block3', 'has', 'color', 'green']\n",
      "[('block3', 'NN'), ('has', 'VBZ'), ('color', 'NN'), ('green', 'NN')]\n",
      "\n",
      "Parts of Speech for each sentence\n",
      "The Parts of Speech:\n",
      "[('block3', 'NN'), ('has', 'VBZ'), ('color', 'NN'), ('green', 'NN')]\n",
      "[('block3', 'BNN'), ('has', 'VBZ'), ('color', 'NN'), ('green', 'VARC')]\n",
      "BLOCK: [('block3', 'BNN')]\n",
      "Block_1: block3\n",
      "COLOR: [('green', 'VARC')]\n",
      "green\n",
      "format_command\n",
      "block3 \n",
      "(has block3 color green)\n",
      "\n",
      "The words are:['block1', 'is', 'at', 'the', 'spot', '8', '3', '0']\n",
      "[('block1', 'NN'), ('is', 'VBZ'), ('at', 'IN'), ('the', 'DT'), ('spot', 'NN'), ('8', 'CD'), ('3', 'CD'), ('0', 'CD')]\n",
      "\n",
      "Parts of Speech for each sentence\n",
      "The Parts of Speech:\n",
      "[('block1', 'NN'), ('is', 'VBZ'), ('at', 'IN'), ('the', 'DT'), ('spot', 'NN'), ('8', 'CD'), ('3', 'CD'), ('0', 'CD')]\n",
      "[('block1', 'BNN'), ('is', 'VARL'), ('at', 'VARL'), ('the', 'DT'), ('spot', 'VARL'), ('8', 'CD'), ('3', 'CD'), ('0', 'CD')]\n",
      "BLOCK: [('block1', 'BNN')]\n",
      "Block_1: block1\n",
      "LOCATION: [('8', 'CD'), ('3', 'CD'), ('0', 'CD')]\n",
      "['8', '3', '0']\n",
      "format_command\n",
      "block1 \n",
      "(has block1 location 8 3 0)\n",
      "\n",
      "The words are:['block3', 'location', 'is', '8', '3', '2']\n",
      "[('block3', 'NN'), ('location', 'NN'), ('is', 'VBZ'), ('8', 'CD'), ('3', 'CD'), ('2', 'CD')]\n",
      "\n",
      "Parts of Speech for each sentence\n",
      "The Parts of Speech:\n",
      "[('block3', 'NN'), ('location', 'NN'), ('is', 'VBZ'), ('8', 'CD'), ('3', 'CD'), ('2', 'CD')]\n",
      "[('block3', 'BNN'), ('location', 'VARL'), ('is', 'VARL'), ('8', 'CD'), ('3', 'CD'), ('2', 'CD')]\n",
      "BLOCK: [('block3', 'BNN')]\n",
      "Block_1: block3\n",
      "LOCATION: [('location', 'VARL'), ('is', 'VARL'), ('8', 'CD'), ('3', 'CD'), ('2', 'CD')]\n",
      "['8', '3', '2']\n",
      "format_command\n",
      "block3 \n",
      "(has block3 location 8 3 2)\n",
      "\n",
      "The words are:['block', '23', 'location', 'is', '8', '4', '0']\n",
      "[('block', 'NN'), ('23', 'CD'), ('location', 'NN'), ('is', 'VBZ'), ('8', 'CD'), ('4', 'CD'), ('0', 'CD')]\n",
      "\n",
      "Parts of Speech for each sentence\n",
      "The Parts of Speech:\n",
      "[('block', 'NN'), ('23', 'CD'), ('location', 'NN'), ('is', 'VBZ'), ('8', 'CD'), ('4', 'CD'), ('0', 'CD')]\n",
      "[('block', 'BNN'), ('23', 'CD'), ('location', 'VARL'), ('is', 'VARL'), ('8', 'CD'), ('4', 'CD'), ('0', 'CD')]\n",
      "BLOCK: [('block', 'BNN'), ('23', 'CD')]\n",
      "Block_1: block23\n",
      "LOCATION: [('location', 'VARL'), ('is', 'VARL'), ('8', 'CD'), ('4', 'CD'), ('0', 'CD')]\n",
      "['8', '4', '0']\n",
      "format_command\n",
      "block23 \n",
      "(has block23 location 8 4 0)\n",
      "\n",
      "The words are:['block', '21', 'location', 'is', '8', '5', '0']\n",
      "[('block', 'NN'), ('21', 'CD'), ('location', 'NN'), ('is', 'VBZ'), ('8', 'CD'), ('5', 'CD'), ('0', 'CD')]\n",
      "\n",
      "Parts of Speech for each sentence\n",
      "The Parts of Speech:\n",
      "[('block', 'NN'), ('21', 'CD'), ('location', 'NN'), ('is', 'VBZ'), ('8', 'CD'), ('5', 'CD'), ('0', 'CD')]\n",
      "[('block', 'BNN'), ('21', 'CD'), ('location', 'VARL'), ('is', 'VARL'), ('8', 'CD'), ('5', 'CD'), ('0', 'CD')]\n",
      "BLOCK: [('block', 'BNN'), ('21', 'CD')]\n",
      "Block_1: block21\n",
      "LOCATION: [('location', 'VARL'), ('is', 'VARL'), ('8', 'CD'), ('5', 'CD'), ('0', 'CD')]\n",
      "['8', '5', '0']\n",
      "format_command\n",
      "block21 \n",
      "(has block21 location 8 5 0)\n",
      "\n",
      "5: SUCCESS\n",
      "6: SUCCESS\n",
      "4: SUCCESS\n",
      "8: SUCCESS\n",
      "7: SUCCESS\n",
      "The words are:['wildcard', '1', 'has', 'location', '4', '2', '0']\n",
      "[('wildcard', 'NN'), ('1', 'CD'), ('has', 'VBZ'), ('location', 'NN'), ('4', 'CD'), ('2', 'CD'), ('0', 'CD')]\n",
      "\n",
      "Parts of Speech for each sentence\n",
      "The Parts of Speech:\n",
      "[('wildcard', 'NN'), ('1', 'CD'), ('has', 'VBZ'), ('location', 'NN'), ('4', 'CD'), ('2', 'CD'), ('0', 'CD')]\n",
      "[('wildcard', 'BNN'), ('1', 'CD'), ('has', 'VBZ'), ('location', 'VARL'), ('4', 'CD'), ('2', 'CD'), ('0', 'CD')]\n",
      "BLOCK: [('wildcard', 'BNN'), ('1', 'CD')]\n",
      "Block_1: wildcard1\n",
      "LOCATION: [('4', 'CD'), ('2', 'CD'), ('0', 'CD')]\n",
      "['4', '2', '0']\n",
      "format_command\n",
      "wildcard1 \n",
      "(has wildcard1 location 4 2 0)\n",
      "\n",
      "The words are:['wildcard2', 'is', 'on', 'top', 'of', 'wildcard1']\n",
      "[('wildcard2', 'NN'), ('is', 'VBZ'), ('on', 'IN'), ('top', 'NN'), ('of', 'IN'), ('wildcard1', 'NN')]\n",
      "\n",
      "Parts of Speech for each sentence\n",
      "The Parts of Speech:\n",
      "[('wildcard2', 'NN'), ('is', 'VBZ'), ('on', 'IN'), ('top', 'NN'), ('of', 'IN'), ('wildcard1', 'NN')]\n",
      "[('wildcard2', 'BNN'), ('is', 'VARL'), ('on', 'VT'), ('top', 'VT'), ('of', 'IN'), ('wildcard1', 'BNN')]\n",
      "BLOCK: [('wildcard2', 'BNN')]\n",
      "Block_1: wildcard2\n",
      "ONTOP: [('on', 'VT')]\n",
      "(S on/VT)\n",
      "ONTOP: [('top', 'VT')]\n",
      "(S top/VT)\n",
      "BLOCK: [('wildcard1', 'BNN')]\n",
      "Block_2: wildcard1\n",
      "format_command\n",
      "wildcard2 wildcard1on-top-of\n",
      "(is wildcard2 wildcard1 on-top-of)\n",
      "\n",
      "The words are:['block1', 'is', 'on', 'top', 'of', 'wildcard2']\n",
      "[('block1', 'NN'), ('is', 'VBZ'), ('on', 'IN'), ('top', 'NN'), ('of', 'IN'), ('wildcard2', 'NN')]\n",
      "\n",
      "Parts of Speech for each sentence\n",
      "The Parts of Speech:\n",
      "[('block1', 'NN'), ('is', 'VBZ'), ('on', 'IN'), ('top', 'NN'), ('of', 'IN'), ('wildcard2', 'NN')]\n",
      "[('block1', 'BNN'), ('is', 'VARL'), ('on', 'VT'), ('top', 'VT'), ('of', 'IN'), ('wildcard2', 'BNN')]\n",
      "BLOCK: [('block1', 'BNN')]\n",
      "Block_1: block1\n",
      "ONTOP: [('on', 'VT')]\n",
      "(S on/VT)\n",
      "ONTOP: [('top', 'VT')]\n",
      "(S top/VT)\n",
      "BLOCK: [('wildcard2', 'BNN')]\n",
      "Block_2: wildcard2\n",
      "format_command\n",
      "block1 wildcard2on-top-of\n",
      "(is block1 wildcard2 on-top-of)\n",
      "\n",
      "The words are:['block', '23', 'is', 'next', 'to', 'block', '21']\n",
      "[('block', 'NN'), ('23', 'CD'), ('is', 'VBZ'), ('next', 'JJ'), ('to', 'TO'), ('block', 'VB'), ('21', 'CD')]\n",
      "\n",
      "Parts of Speech for each sentence\n",
      "The Parts of Speech:\n",
      "[('block', 'NN'), ('23', 'CD'), ('is', 'VBZ'), ('next', 'JJ'), ('to', 'TO'), ('block', 'VB'), ('21', 'CD')]\n",
      "[('block', 'BNN'), ('23', 'CD'), ('is', 'VARL'), ('next', 'VS'), ('to', 'TO'), ('block', 'BNN'), ('21', 'CD')]\n",
      "BLOCK: [('block', 'BNN'), ('23', 'CD')]\n",
      "Block_1: block23\n",
      "SIDE: [('next', 'VS')]\n",
      "BLOCK: [('block', 'BNN'), ('21', 'CD')]\n",
      "Block_2: block21\n",
      "format_command\n",
      "block23 block21side-by-side\n",
      "(is block23 block21 side-by-side)\n",
      "\n",
      "The words are:['move', 'block', '21', 'to', '3', '5', '0']\n",
      "[('move', 'NN'), ('block', 'NN'), ('21', 'CD'), ('to', 'TO'), ('3', 'CD'), ('5', 'CD'), ('0', 'CD')]\n",
      "\n",
      "Parts of Speech for each sentence\n",
      "The Parts of Speech:\n",
      "[('move', 'NN'), ('block', 'NN'), ('21', 'CD'), ('to', 'TO'), ('3', 'CD'), ('5', 'CD'), ('0', 'CD')]\n",
      "[('move', 'NN'), ('block', 'BNN'), ('21', 'CD'), ('to', 'TO'), ('3', 'CD'), ('5', 'CD'), ('0', 'CD')]\n",
      "BLOCK: [('block', 'BNN'), ('21', 'CD')]\n",
      "Block_1: block21\n",
      "LOCATION: [('3', 'CD'), ('5', 'CD'), ('0', 'CD')]\n",
      "['3', '5', '0']\n",
      "format_command\n",
      "block21 \n",
      "(has block21 location 3 5 0)\n",
      "\n",
      "7: SUCCESS\n",
      "6: SUCCESS\n"
     ]
    }
   ],
   "source": [
    "#Read in initial file\n",
    "outputStart = \"aStarSearch/nlp_outputs/start1.txt\"\n",
    "readinfile(\"nlp_tests/start1.txt\", outputStart)\n",
    "\n",
    "#Read in goal file\n",
    "outputGoal = \"aStarSearch/nlp_outputs/goal1.txt\"\n",
    "readinfile(\"nlp_tests/goal1.txt\", outputGoal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aStarSearch/nlp_outputs/start1.txt\n",
      "aStarSearch/nlp_outputs/goal1.txt\n",
      "\n",
      "Searching...\n",
      "\n",
      "END STATE:\n",
      "        Coordinates Properties\n",
      "Block                         \n",
      "block1    (4, 2, 2)      [red]\n",
      "block2    (4, 2, 1)         []\n",
      "block21   (4, 2, 0)         []\n",
      "block23   (5, 2, 0)         []\n",
      "block3    (7, 8, 0)    [green]\n",
      "['command grab block3', 'command carry block3 -1 -1 1', 'command carry block3 -1 0 0', 'command carry block3 0 -1 0', 'command carry block3 0 1 -1', 'command carry block3 0 1 0', 'command carry block3 -1 1 0', 'command carry block3 1 1 -1', 'command carry block3 -1 1 0', 'command carry block3 1 1 -1', 'command release block3', 'command grab block2', 'command carry block2 1 1 -1', 'command carry block2 -1 1 1', 'command release block2', 'command grab block1', 'command carry block1 1 1 1', 'command carry block1 -1 1 1', 'command release block1', 'command slide block21 -1 -1', 'command slide block3 1 0', 'command slide block23 -1 -1', 'command slide block21 -1 -1', 'command slide block23 -1 -1', 'command slide block21 -1 -1', 'command slide block23 -1 1', 'command slide block3 0 1', 'command slide block21 -1 0', 'command slide block23 0 -1']\n",
      "LENGTH: 29\n",
      "\n",
      "END STATE:\n",
      "        Coordinates Properties\n",
      "Block                         \n",
      "block1    (4, 2, 2)      [red]\n",
      "block2    (5, 3, 0)         []\n",
      "block21   (4, 2, 0)         []\n",
      "block23   (4, 3, 0)         []\n",
      "block3    (4, 2, 1)    [green]\n",
      "['command grab block3', 'command carry block3 1 0 -1', 'command carry block3 0 1 -1', 'command carry block3 -1 1 1', 'command release block3', 'command slide block21 -1 -1', 'command slide block23 -1 1', 'command slide block23 -1 -1', 'command slide block21 -1 -1', 'command slide block23 -1 -1', 'command slide block1 0 -1', 'command slide block21 -1 -1', 'command slide block1 -1 -1', 'command slide block1 -1 1', 'command slide block21 -1 0', 'command slide block23 -1 0', 'command grab block2', 'command carry block2 -1 1 -1', 'command release block2', 'command grab block1', 'command carry block1 -1 1 1', 'command carry block1 -1 -1 1']\n",
      "LENGTH: 22\n",
      "\n",
      "END STATE:\n",
      "        Coordinates Properties\n",
      "Block                         \n",
      "block1    (4, 2, 2)      [red]\n",
      "block2    (4, 2, 1)         []\n",
      "block21   (4, 2, 0)         []\n",
      "block23   (4, 3, 0)         []\n",
      "block3    (4, 3, 1)    [green]\n",
      "['command grab block3', 'command carry block3 0 1 -1', 'command release block3', 'command grab block2', 'command carry block2 1 1 -1', 'command carry block2 -1 1 1', 'command release block2', 'command grab block1', 'command carry block1 1 1 1', 'command carry block1 -1 1 1', 'command release block1', 'command slide block21 -1 -1', 'command slide block23 -1 -1', 'command slide block21 -1 -1', 'command slide block23 -1 -1', 'command slide block21 -1 -1', 'command slide block23 -1 1', 'command slide block21 -1 0', 'command slide block23 -1 0']\n",
      "LENGTH: 19\n",
      "\n",
      "END STATE:\n",
      "        Coordinates Properties\n",
      "Block                         \n",
      "block1    (4, 2, 2)      [red]\n",
      "block2    (4, 2, 1)         []\n",
      "block21   (8, 5, 0)         []\n",
      "block23   (8, 4, 0)         []\n",
      "block3    (4, 2, 0)    [green]\n",
      "['command grab block3', 'command carry block3 -1 0 -1', 'command carry block3 -1 -1 -1', 'command release block3', 'command grab block2', 'command carry block2 -1 0 -1', 'command carry block2 -1 -1 1', 'command release block2', 'command grab block1', 'command carry block1 -1 0 1', 'command carry block1 -1 -1 1', 'command release block1', 'command slide block3 -1 0', 'command slide block3 -1 0']\n",
      "LENGTH: 14\n",
      "\n",
      "BEST:\n",
      "        Coordinates Properties\n",
      "Block                         \n",
      "block1    (4, 2, 2)      [red]\n",
      "block2    (4, 2, 1)         []\n",
      "block21   (8, 5, 0)         []\n",
      "block23   (8, 4, 0)         []\n",
      "block3    (4, 2, 0)    [green]\n",
      "['command grab block3', 'command carry block3 -1 0 -1', 'command carry block3 -1 -1 -1', 'command release block3', 'command grab block2', 'command carry block2 -1 0 -1', 'command carry block2 -1 -1 1', 'command release block2', 'command grab block1', 'command carry block1 -1 0 1', 'command carry block1 -1 -1 1', 'command release block1', 'command slide block3 -1 0', 'command slide block3 -1 0']\n",
      "LENGTH: 14\n"
     ]
    }
   ],
   "source": [
    "#!{sys.executable} -m pip install pandas\n",
    "#import pandas as pd\n",
    "%run -i \"./aStarSearch/aStarSearch.py\" $outputStart $outputGoal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}