{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import io\n",
    "\n",
    "# you'll need to run nltk.download() and download all packages\n",
    "#nltk.download_shell()\n",
    "#nltk.download('stopwords')\n",
    "#nltk.data.path.append('D:\\\\JacobSchool\\\\CS540\\\\nltk_data')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets from http://www.iaees.org/publications/journals/selforganizology/articles/2016-3(3)/algorithm-to-transform-natural-language-into-SQL-queries.pdf\n",
    "Escape Word Set<br/>\n",
    "Expression Mapping Set<br/>\n",
    "Noun Set<br/>\n",
    "Verb Set<br/>\n",
    "Semantic Set<br/>\n",
    "Variable Set<br/>\n",
    "Relation Set<br/>\n",
    "Attribute Set<br/>\n",
    "Conjunction Set<br/>\n",
    "This is all the sets for words and rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "escape_words = set(stopwords.words('english'))#[\"a\", \"an\", \"the\", \"which\", \"is\", \"of\", \"with\", \"to\", \"for\", \"are\", \"and\", \"should\", \"be\"]\n",
    "\n",
    "rules_on_top_of = []\n",
    "\n",
    "rules_side_by_side = []\n",
    "\n",
    "nouns = [\"block\", \"wildcard\", \"block0\", \"block1\", \"block2\", \"block3\", \"block4\", \"block5\", \"block6\", \"block7\", \"block8\", \"block9\" \\\n",
    "         \"block10\", \"block11\", \"block12\", \"block13\", \"block14\", \"block15\", \"block16\", \"block17\", \"block18\", \"block19\" \\\n",
    "         \"block20\", \"block21\", \"block22\", \"block23\", \"block24\", \"block25\", \"block26\", \"block27\", \"block28\", \"block29\" \\\n",
    "         \"block30\", \"block31\", \"block32\", \"block33\", \"block34\", \"block35\", \"block36\", \"block37\", \"block38\", \"block39\" \\\n",
    "         \"block40\", \"block41\", \"block42\", \"block43\", \"block44\", \"block45\", \"block46\", \"block47\", \"block48\", \"block49\" \\\n",
    "         \"block50\", \"block51\", \"block52\", \"block53\", \"block54\", \"block55\", \"block56\", \"block57\", \"block58\", \"block59\" \\\n",
    "         \"block60\", \"block61\", \"block62\", \"block63\", \"block64\", \"block65\", \"block66\", \"block67\", \"block68\", \"block69\" \\\n",
    "         \"block70\", \"block71\", \"block72\", \"block73\", \"block74\", \"block75\", \"block76\", \"block77\", \"block78\", \"block79\" \\\n",
    "         \"block80\", \"block81\", \"block82\", \"block83\", \"block84\", \"block85\", \"block86\", \"block87\", \"block88\", \"block89\" \\\n",
    "         \"block90\", \"block91\", \"block92\", \"block93\", \"block94\", \"block95\", \"block96\", \"block97\", \"block98\", \"block99\" \\\n",
    "         \"wildcard0\", \"wildcard1\", \"wildcard2\", \"wildcard3\", \"wildcard4\", \"wildcard5\", \"wildcard6\", \"wildcard7\", \"wildcard8\", \"wildcard9\" \\\n",
    "         \"wildcard10\", \"wildcard11\", \"wildcard12\", \"wildcard13\", \"wildcard14\", \"wildcard15\", \"wildcard16\", \"wildcard17\", \"wildcard18\", \"wildcard19\" \\\n",
    "         \"wildcard20\", \"wildcard21\", \"wildcard22\", \"wildcard23\", \"wildcard24\", \"wildcard25\", \"wildcard26\", \"wildcard27\", \"wildcard28\", \"wildcard29\" \\\n",
    "         \"wildcard30\", \"wildcard31\", \"wildcard32\", \"wildcard33\", \"wildcard34\", \"wildcard35\", \"wildcard36\", \"wildcard37\", \"wildcard38\", \"wildcard39\" \\\n",
    "         \"wildcard40\", \"wildcard41\", \"wildcard42\", \"wildcard43\", \"wildcard44\", \"wildcard45\", \"wildcard46\", \"wildcard47\", \"wildcard48\", \"wildcard49\" \\\n",
    "         \"wildcard50\", \"wildcard51\", \"wildcard52\", \"wildcard53\", \"wildcard54\", \"wildcard55\", \"wildcard56\", \"wildcard57\", \"wildcard58\", \"wildcard59\" \\\n",
    "         \"wildcard60\", \"wildcard61\", \"wildcard62\", \"wildcard63\", \"wildcard64\", \"wildcard65\", \"wildcard66\", \"wildcard67\", \"wildcard68\", \"wildcard69\" \\\n",
    "         \"wildcard70\", \"wildcard71\", \"wildcard72\", \"wildcard73\", \"wildcard74\", \"wildcard75\", \"wildcard76\", \"wildcard77\", \"wildcard78\", \"wildcard79\" \\\n",
    "         \"wildcard80\", \"wildcard81\", \"wildcard82\", \"wildcard83\", \"wildcard84\", \"wildcard85\", \"wildcard86\", \"wildcard87\", \"wildcard88\", \"wildcard89\" \\\n",
    "         \"wildcard90\", \"wildcard91\", \"wildcard92\", \"wildcard93\", \"wildcard94\", \"wildcard95\", \"wildcard96\", \"wildcard97\", \"wildcard98\", \"wildcard99\" ]\n",
    "\n",
    "verbs_top = [\"top\", \"above\", \"over\", \"on\"]\n",
    "verbs_below = [\"below\", \"underneath\",  \"under\"]\n",
    "verbs_side = [\"side\", \"neighboring\", \"beside\", \"next\"]\n",
    "\n",
    "variables_colors = [\"amber\", \"amethyst\", \"apricot\", \"aquamarine\", \"azure\", \"beige\", \"black\", \"blue\", \"blush\", \"bronze\", \"brown\", \"burgundy\", \"byzantium\", \"carmine\", \"cerise\", \"cerulean\", \"champagne\", \"chocolate\", \"coffee\", \"copper\", \"coral\", \"crimson\", \"cyan\", \"emerald\", \"erin\", \"gold\", \"gray\", \"green\", \"harlequin\", \"indigo\", \"ivory\", \"jade\", \"lavender\", \"lemon\", \"lilac\", \"lime\", \"magenta\", \"maroon\", \"mauve\", \"navy\", \"ochre\", \"olive\", \"orange\", \"orchid\", \"peach\", \"pearl\", \"periwinkle\", \"pink\", \"plum\", \"puce\", \"purple\", \"raspberry\", \"red\", \"rose\", \"ruby\", \"salmon\", \"sangria\", \"sapphire\", \"scarlet\", \"silver\", \"tan\", \"taupe\", \"teal\", \"turquoise\", \"ultramarine\", \"violet\", \"viridian\", \"white\", \"yellow\"]\n",
    "variables_location = [\"0\",\"zero\",\"1\", \"one\", \"2\", \"two\", \"3\", \"three\", \"4\", \"four\", \"5\", \"five\", \"6\", \"six\", \"7\", \"seven\", \"8\", \"eight\", \"9\", \"nine\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Tags:<br/>\n",
    "NN &rightarrow; Noun<br/>\n",
    "VT &rightarrow; Verb Top<br/>\n",
    "VB &rightarrow; Verb Below<br/>\n",
    "VS &rightarrow; Verb Side<br/>\n",
    "VarC &rightarrow; Variable Color<br/>\n",
    "VarL &rightarrow; Variable Location<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBlockWorld(tagged_sentence, outputfile):\n",
    "    block1=\"\"\n",
    "    block2=\"\"\n",
    "    relation=\"\"\n",
    "    command=\"\"\n",
    "    location=\"\"\n",
    "    color=\"\"\n",
    "    swap_on_top_of = False\n",
    "    print('tagged sentence')\n",
    "    print(tagged_sentence)\n",
    "    #Find the first block, should be the block\n",
    "    for ts in tagged_sentence:\n",
    "        if (ts[1] == \"VT\"):\n",
    "            relation = \"on-top-of\"\n",
    "        \n",
    "        if (ts[1] == \"VS\"):\n",
    "            relation = \"side-by-side\"\n",
    "        \n",
    "        if (ts[1] == \"VB\"):\n",
    "            swap_on_top_of = True\n",
    "            relation = \"on-top-of\"\n",
    "            \n",
    "        if (ts[1] == \"VarL\"):\n",
    "            if(location==\"\"): \n",
    "                location+=ts[0]\n",
    "            else:\n",
    "                location+=(\" \"+ts[0])\n",
    "            \n",
    "        \n",
    "        if ((\"block\" in ts[0]) or (\"wildcard\" in ts[0])) and block1 == \"\":\n",
    "            block1=ts[0]\n",
    "        \n",
    "        if (ts[0] != block1) and ((\"block\" in ts[0]) or (\"wildcard\" in ts[0])):\n",
    "                block2=ts[0]\n",
    "        if (ts[1] == \"VarC\"):\n",
    "            color = ts[0]\n",
    "            \n",
    "\n",
    "    thecommand = \"\"\n",
    "    #Create the command for an is relation\n",
    "    if block1 and block2 and relation:\n",
    "        if swap_on_top_of:\n",
    "            thecommand = \"(is %s %s %s)\" %(block2, block1, relation)\n",
    "        else:\n",
    "            thecommand = \"(is %s %s %s)\" %(block1, block2, relation)\n",
    "    \n",
    "    if block1 and color:\n",
    "        thecommand = \"(has %s color %s)\" % (block1,color)\n",
    "\n",
    "    if block1 and location and (len(location)==5):\n",
    "            thecommand = \"(has %s location %s)\" % (block1,location)\n",
    "\n",
    "        \n",
    "    if thecommand != \"\":\n",
    "        print(thecommand)\n",
    "        with open(outputfile, \"a\") as myfile:\n",
    "            myfile.write(thecommand+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.remove(\"blockworld.txt\") if os.path.exists(\"blockworld.txt\") else None\n",
    "#os.remove(\"goalworld.txt\") if os.path.exists(\"goalworld.txt\") else None\n",
    "\n",
    "def readinfile(inputfile, outputfile):\n",
    "    #os.remove(inputfile) if os.path.exists(inputfile) else None\n",
    "    os.remove(outputfile) if os.path.exists(outputfile) else None\n",
    "\n",
    "    commandFile = open(inputfile) \n",
    "    data = commandFile.read()# Use this to read file content as a stream: \n",
    "    commandFile.close()\n",
    "\n",
    "    sentences = sent_tokenize(data)\n",
    "    #print(sentences)\n",
    "    parts_of_speech = []\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence)\n",
    "        temp = []\n",
    "        for w in words:\n",
    "            temp.append(w.lower())\n",
    "        words = temp[0:-1]\n",
    "        temp = []\n",
    "        \n",
    "        for w in words:\n",
    "            if(w in nouns):\n",
    "                temp.append((w, \"NN\"))\n",
    "            elif(w in verbs_top):\n",
    "                temp.append((w, \"VT\"))\n",
    "            elif(w in verbs_below):\n",
    "                temp.append((w, \"VB\"))\n",
    "            elif(w in verbs_side):\n",
    "                temp.append((w, \"VS\"))\n",
    "            elif(w in variables_colors):\n",
    "                temp.append((w, \"VarC\"))\n",
    "            elif(w in variables_location):\n",
    "                temp.append((w, \"VarL\"))\n",
    "        tagged_words = temp\n",
    "        #print(tagged_words)\n",
    "        createBlockWorld(tagged_words, outputfile)\n",
    "    \n",
    "    #Part of Speech tagging\n",
    "    #parts_of_speech.append(nltk.pos_tag(words))\n",
    "    \n",
    "#print(\"\\nParts of Speech for each sentence\")\n",
    "#for p in parts_of_speech:\n",
    "#    print(p)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagged sentence\n",
      "[('block1', 'NN'), ('red', 'VarC')]\n",
      "(has block1 color red)\n",
      "tagged sentence\n",
      "[('block2', 'NN'), ('8', 'VarL'), ('3', 'VarL'), ('1', 'VarL')]\n",
      "(has block2 location 8 3 1)\n",
      "tagged sentence\n",
      "[('block3', 'NN'), ('green', 'VarC')]\n",
      "(has block3 color green)\n",
      "tagged sentence\n",
      "[('block1', 'NN'), ('8', 'VarL'), ('3', 'VarL'), ('0', 'VarL')]\n",
      "(has block1 location 8 3 0)\n",
      "tagged sentence\n",
      "[('block3', 'NN'), ('blue', 'VarC')]\n",
      "(has block3 color blue)\n",
      "tagged sentence\n",
      "[('block3', 'NN'), ('8', 'VarL'), ('3', 'VarL'), ('2', 'VarL')]\n",
      "(has block3 location 8 3 2)\n",
      "tagged sentence\n",
      "[('wildcard1', 'NN'), ('4', 'VarL'), ('2', 'VarL'), ('0', 'VarL')]\n",
      "(has wildcard1 location 4 2 0)\n",
      "tagged sentence\n",
      "[('wildcard2', 'NN'), ('on', 'VT'), ('top', 'VT'), ('wildcard1', 'NN')]\n",
      "(is wildcard2 wildcard1 on-top-of)\n",
      "tagged sentence\n",
      "[('block1', 'NN'), ('on', 'VT'), ('top', 'VT'), ('wildcard2', 'NN')]\n",
      "(is block1 wildcard2 on-top-of)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Read in initial file\n",
    "outputStart = \"aStarSearch/nlp_outputs/start1.txt\"\n",
    "readinfile(\"nlp_tests/start1.txt\", outputStart)\n",
    "\n",
    "#Read in goal file\n",
    "outputGoal = \"aStarSearch/nlp_outputs/goal1.txt\"\n",
    "readinfile(\"nlp_tests/goal1.txt\", outputGoal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aStarSearch/nlp_outputs/start1.txt\n",
      "aStarSearch/nlp_outputs/goal1.txt\n",
      "\n",
      "Searching...\n",
      "\n",
      "END STATE:\n",
      "       Coordinates     Properties\n",
      "Block                            \n",
      "block1   (4, 2, 2)          [red]\n",
      "block2   (4, 2, 1)             []\n",
      "block3   (4, 2, 0)  [green, blue]\n",
      "['command grab block3', 'command carry block3 -1 1 -1', 'command carry block3 -1 -1 -1', 'command release block3', 'command grab block2', 'command carry block2 -1 -1 -1', 'command carry block2 -1 1 1', 'command release block2', 'command grab block1', 'command carry block1 -1 1 1', 'command carry block1 -1 -1 1', 'command release block1', 'command slide block3 -1 0', 'command slide block3 -1 -1']\n",
      "LENGTH: 14\n",
      "\n",
      "BEST:\n",
      "       Coordinates     Properties\n",
      "Block                            \n",
      "block1   (4, 2, 2)          [red]\n",
      "block2   (4, 2, 1)             []\n",
      "block3   (4, 2, 0)  [green, blue]\n",
      "['command grab block3', 'command carry block3 -1 1 -1', 'command carry block3 -1 -1 -1', 'command release block3', 'command grab block2', 'command carry block2 -1 -1 -1', 'command carry block2 -1 1 1', 'command release block2', 'command grab block1', 'command carry block1 -1 1 1', 'command carry block1 -1 -1 1', 'command release block1', 'command slide block3 -1 0', 'command slide block3 -1 -1']\n",
      "LENGTH: 14\n"
     ]
    }
   ],
   "source": [
    "#!{sys.executable} -m pip install pandas\n",
    "#import pandas as pd\n",
    "%run -i \"./aStarSearch/aStarSearch.py\" $outputStart $outputGoal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
